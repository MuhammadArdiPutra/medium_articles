{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b0eac7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codeblock 1\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3070efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codeblock 2\n",
    "BATCH_SIZE        = 1\n",
    "IMAGE_SIZE        = 224\n",
    "IN_CHANNELS       = 3\n",
    "NUM_CLASSES       = 1000\n",
    "WIDTH_MULTIPLIER  = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1da9f824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codeblock 3\n",
    "class Conv(nn.Module):\n",
    "    def __init__(self, first=False):      #(1)\n",
    "        super().__init__()\n",
    "        \n",
    "        if first:\n",
    "            in_channels = 3               #(2)\n",
    "            out_channels = int(32*WIDTH_MULTIPLIER)          #(3)\n",
    "            kernel_size = 3               #(4)\n",
    "            stride = 2                    #(5)\n",
    "            padding = 1                   #(6)\n",
    "        else:\n",
    "            in_channels  = int(320*WIDTH_MULTIPLIER)         #(7)\n",
    "            out_channels = int(1280*WIDTH_MULTIPLIER)        #(8)\n",
    "            kernel_size = 1               #(9)\n",
    "            stride = 1                    #(10)\n",
    "            padding = 0                   #(11)\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channels=in_channels,       #(12)\n",
    "                              out_channels=out_channels, \n",
    "                              kernel_size=kernel_size,\n",
    "                              stride=stride, \n",
    "                              padding=padding, \n",
    "                              bias=False)\n",
    "        self.bn = nn.BatchNorm2d(num_features=out_channels)  #(13)\n",
    "        self.relu6 = nn.ReLU6()           #(14)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu6(self.bn(self.conv(x)))                #(15)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7e8d4dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 112, 112])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Codeblock 4\n",
    "conv = Conv(first=True)\n",
    "x = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "out = conv(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d13c073f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1280, 7, 7])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Codeblock 5\n",
    "conv = Conv(first=False)\n",
    "x = torch.randn(1, int(320*WIDTH_MULTIPLIER), 7, 7)\n",
    "\n",
    "out = conv(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de5f97b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codeblock 6\n",
    "class InvResidualS2(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, t):         #(1)\n",
    "        super().__init__()\n",
    "        \n",
    "        in_channels  = int(in_channels*WIDTH_MULTIPLIER)      #(2)\n",
    "        out_channels = int(out_channels*WIDTH_MULTIPLIER)     #(3)\n",
    "        \n",
    "        self.pwconv0 = nn.Conv2d(in_channels=in_channels,     #(4)\n",
    "                                 out_channels=in_channels*t,\n",
    "                                 kernel_size=1, \n",
    "                                 stride=1, \n",
    "                                 bias=False)\n",
    "        \n",
    "        self.bn_pwconv0 = nn.BatchNorm2d(num_features=in_channels*t)\n",
    "        \n",
    "        self.dwconv = nn.Conv2d(in_channels=in_channels*t,    #(5)\n",
    "                                out_channels=in_channels*t, \n",
    "                                kernel_size=3,                #(6)\n",
    "                                stride=2, \n",
    "                                padding=1,\n",
    "                                groups=in_channels*t,         #(7)\n",
    "                                bias=False)\n",
    "        \n",
    "        self.bn_dwconv = nn.BatchNorm2d(num_features=in_channels*t)\n",
    "        \n",
    "        self.pwconv1 = nn.Conv2d(in_channels=in_channels*t,   #(8)\n",
    "                                 out_channels=out_channels, \n",
    "                                 kernel_size=1, \n",
    "                                 stride=1, \n",
    "                                 bias=False)\n",
    "        \n",
    "        self.bn_pwconv1 = nn.BatchNorm2d(num_features=out_channels)\n",
    "        \n",
    "        self.relu6 = nn.ReLU6()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #print('original\\t\\t:', x.shape)\n",
    "        \n",
    "        x = self.pwconv0(x)\n",
    "        #print('after pwconv0\\t\\t:', x.shape)\n",
    "        x = self.bn_pwconv0(x)\n",
    "        #print('after bn0_pwconv0\\t:', x.shape)\n",
    "        x = self.relu6(x)\n",
    "        #print('after relu\\t\\t:', x.shape)\n",
    "        \n",
    "        x = self.dwconv(x)\n",
    "        #print('after dwconv\\t\\t:', x.shape)\n",
    "        x = self.bn_dwconv(x)\n",
    "        #print('after bn_dwconv\\t\\t:', x.shape)\n",
    "        x = self.relu6(x)\n",
    "        #print('after relu\\t\\t:', x.shape)\n",
    "        \n",
    "        x = self.pwconv1(x)\n",
    "        #print('after pwconv1\\t\\t:', x.shape)\n",
    "        x = self.bn_pwconv1(x)\n",
    "        #print('after bn_pwconv1\\t:', x.shape)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2dd11926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original\t\t: torch.Size([1, 16, 112, 112])\n",
      "after pwconv0\t\t: torch.Size([1, 96, 112, 112])\n",
      "after bn0_pwconv0\t: torch.Size([1, 96, 112, 112])\n",
      "after relu\t\t: torch.Size([1, 96, 112, 112])\n",
      "after dwconv\t\t: torch.Size([1, 96, 56, 56])\n",
      "after bn_dwconv\t\t: torch.Size([1, 96, 56, 56])\n",
      "after relu\t\t: torch.Size([1, 96, 56, 56])\n",
      "after pwconv1\t\t: torch.Size([1, 24, 56, 56])\n",
      "after bn_pwconv1\t: torch.Size([1, 24, 56, 56])\n"
     ]
    }
   ],
   "source": [
    "# Codeblock 7\n",
    "inv_residual_s2 = InvResidualS2(in_channels=16, out_channels=24, t=6)\n",
    "x = torch.randn(1, int(16*WIDTH_MULTIPLIER), 112, 112)\n",
    "\n",
    "out = inv_residual_s2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "542ef506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codeblock 8\n",
    "class InvResidualS1(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, t):\n",
    "        super().__init__()\n",
    "        \n",
    "        in_channels  = int(in_channels*WIDTH_MULTIPLIER)    #(1)\n",
    "        out_channels = int(out_channels*WIDTH_MULTIPLIER)   #(2)\n",
    "        \n",
    "        self.in_channels  = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        self.pwconv0 = nn.Conv2d(in_channels=in_channels, \n",
    "                                 out_channels=in_channels*t, \n",
    "                                 kernel_size=1, \n",
    "                                 stride=1, \n",
    "                                 bias=False)\n",
    "        \n",
    "        self.bn_pwconv0 = nn.BatchNorm2d(num_features=in_channels*t)\n",
    "        \n",
    "        self.dwconv = nn.Conv2d(in_channels=in_channels*t, \n",
    "                                out_channels=in_channels*t, \n",
    "                                kernel_size=3, \n",
    "                                stride=1,            #(3)\n",
    "                                padding=1,\n",
    "                                groups=in_channels*t, \n",
    "                                bias=False)\n",
    "        \n",
    "        self.bn_dwconv = nn.BatchNorm2d(num_features=in_channels*t)\n",
    "        \n",
    "        self.pwconv1 = nn.Conv2d(in_channels=in_channels*t, \n",
    "                                 out_channels=out_channels, \n",
    "                                 kernel_size=1, \n",
    "                                 stride=1, \n",
    "                                 bias=False)\n",
    "        \n",
    "        self.bn_pwconv1 = nn.BatchNorm2d(num_features=out_channels)\n",
    "        \n",
    "        self.relu6 = nn.ReLU6()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        if self.in_channels == self.out_channels:    #(4)\n",
    "            residual = x          #(5)\n",
    "            #print(f'residual\\t\\t: {residual.size()}')\n",
    "        \n",
    "        x = self.pwconv0(x)\n",
    "        #print('after pwconv0\\t\\t:', x.shape)\n",
    "        x = self.bn_pwconv0(x)\n",
    "        #print('after bn_pwconv0\\t:', x.shape)\n",
    "        x = self.relu6(x)\n",
    "        #print('after relu\\t\\t:', x.shape)\n",
    "        \n",
    "        x = self.dwconv(x)\n",
    "        #print('after dwconv\\t\\t:', x.shape)\n",
    "        x = self.bn_dwconv(x)\n",
    "        #print('after bn_dwconv\\t\\t:', x.shape)\n",
    "        x = self.relu6(x)\n",
    "        #print('after relu\\t\\t:', x.shape)\n",
    "        \n",
    "        x = self.pwconv1(x)\n",
    "        #print('after pwconv1\\t\\t:', x.shape)\n",
    "        x = self.bn_pwconv1(x)\n",
    "        #print('after bn_pwconv1\\t:', x.shape)\n",
    "        \n",
    "        if self.in_channels == self.out_channels:\n",
    "            x = x + residual      #(6)\n",
    "            #print('after summation\\t\\t:', x.shape)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9cf6468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "residual\t\t: torch.Size([1, 24, 56, 56])\n",
      "after pwconv0\t\t: torch.Size([1, 144, 56, 56])\n",
      "after bn_pwconv0\t: torch.Size([1, 144, 56, 56])\n",
      "after relu\t\t: torch.Size([1, 144, 56, 56])\n",
      "after dwconv\t\t: torch.Size([1, 144, 56, 56])\n",
      "after bn_dwconv\t\t: torch.Size([1, 144, 56, 56])\n",
      "after relu\t\t: torch.Size([1, 144, 56, 56])\n",
      "after pwconv1\t\t: torch.Size([1, 24, 56, 56])\n",
      "after bn_pwconv1\t: torch.Size([1, 24, 56, 56])\n",
      "after summation\t\t: torch.Size([1, 24, 56, 56])\n"
     ]
    }
   ],
   "source": [
    "# Codeblock 9\n",
    "inv_residual_s1 = InvResidualS1(in_channels=24, out_channels=24, t=6)\n",
    "x = torch.randn(1, int(24*WIDTH_MULTIPLIER), 56, 56)\n",
    "\n",
    "out = inv_residual_s1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5575dd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codeblock 10\n",
    "class MobileNetV2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Input shape: 3x224x224\n",
    "        self.first_conv = Conv(first=True)\n",
    "        \n",
    "        # Input shape: 32x112x112\n",
    "        self.inv_residual0 = InvResidualS1(in_channels=32, \n",
    "                                           out_channels=16, \n",
    "                                           t=1)\n",
    "        \n",
    "        # Input shape: 16x112x112\n",
    "        self.inv_residual1 = nn.ModuleList([InvResidualS2(in_channels=16, \n",
    "                                                          out_channels=24, \n",
    "                                                          t=6)])\n",
    "        \n",
    "        self.inv_residual1.append(InvResidualS1(in_channels=24, \n",
    "                                                out_channels=24, \n",
    "                                                t=6))\n",
    "        \n",
    "        # Input shape: 24x56x56\n",
    "        self.inv_residual2 = nn.ModuleList([InvResidualS2(in_channels=24, \n",
    "                                                          out_channels=32, \n",
    "                                                          t=6)])\n",
    "        \n",
    "        for _ in range(2):\n",
    "            self.inv_residual2.append(InvResidualS1(in_channels=32, \n",
    "                                                    out_channels=32, \n",
    "                                                    t=6))\n",
    "        \n",
    "        # Input shape: 32x28x28\n",
    "        self.inv_residual3 = nn.ModuleList([InvResidualS2(in_channels=32, \n",
    "                                                          out_channels=64, \n",
    "                                                          t=6)])\n",
    "        \n",
    "        for _ in range(3):\n",
    "            self.inv_residual3.append(InvResidualS1(in_channels=64, \n",
    "                                                    out_channels=64, \n",
    "                                                    t=6))\n",
    "            \n",
    "        # Input shape: 64x14x14\n",
    "        self.inv_residual4 = nn.ModuleList([InvResidualS1(in_channels=64, \n",
    "                                                          out_channels=96, \n",
    "                                                          t=6)])\n",
    "        \n",
    "        for _ in range(2):\n",
    "            self.inv_residual4.append(InvResidualS1(in_channels=96, \n",
    "                                                    out_channels=96, \n",
    "                                                    t=6))\n",
    "        \n",
    "        \n",
    "        # Input shape: 96x14x14\n",
    "        self.inv_residual5 = nn.ModuleList([InvResidualS2(in_channels=96, \n",
    "                                                          out_channels=160, \n",
    "                                                          t=6)])\n",
    "        \n",
    "        for _ in range(2):\n",
    "            self.inv_residual5.append(InvResidualS1(in_channels=160, \n",
    "                                                    out_channels=160, \n",
    "                                                    t=6))\n",
    "        \n",
    "        # Input shape: 160x7x7\n",
    "        self.inv_residual6 = InvResidualS1(in_channels=160, \n",
    "                                           out_channels=320, \n",
    "                                           t=6)\n",
    "        \n",
    "        # Input shape: 320x7x7\n",
    "        self.last_conv = Conv(first=False)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(output_size=(1,1))        #(1)\n",
    "        self.dropout = nn.Dropout(p=0.2)                              #(2)\n",
    "        self.fc = nn.Linear(in_features=int(1280*WIDTH_MULTIPLIER),   #(3)\n",
    "                            out_features=1000)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.first_conv(x)\n",
    "        #print(f\"after first_conv\\t: {x.shape}\")\n",
    "        \n",
    "        x = self.inv_residual0(x)\n",
    "        #print(f\"after inv_residual0\\t: {x.shape}\")\n",
    "            \n",
    "        for i, layer in enumerate(self.inv_residual1):\n",
    "            x = layer(x)\n",
    "            #print(f\"after inv_residual1 #{i}\\t: {x.shape}\")\n",
    "            \n",
    "        for i, layer in enumerate(self.inv_residual2):\n",
    "            x = layer(x)\n",
    "            #print(f\"after inv_residual2 #{i}\\t: {x.shape}\")\n",
    "            \n",
    "        for i, layer in enumerate(self.inv_residual3):\n",
    "            x = layer(x)\n",
    "            #print(f\"after inv_residual3 #{i}\\t: {x.shape}\")\n",
    "            \n",
    "        for i, layer in enumerate(self.inv_residual4):\n",
    "            x = layer(x)\n",
    "            #print(f\"after inv_residual4 #{i}\\t: {x.shape}\")\n",
    "            \n",
    "        for i, layer in enumerate(self.inv_residual5):\n",
    "            x = layer(x)\n",
    "            #print(f\"after inv_residual5 #{i}\\t: {x.shape}\")\n",
    "        \n",
    "        x = self.inv_residual6(x)\n",
    "        #print(f\"after inv_residual6\\t: {x.shape}\")\n",
    "        \n",
    "        x = self.last_conv(x)\n",
    "        #print(f\"after last_conv\\t\\t: {x.shape}\")\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        #print(f\"after avgpool\\t\\t: {x.shape}\")\n",
    "        \n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        #print(f\"after flatten\\t\\t: {x.shape}\")\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        #print(f\"after dropout\\t\\t: {x.shape}\")\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        #print(f\"after fc\\t\\t: {x.shape}\")\n",
    "                \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5dd977ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after first_conv\t: torch.Size([1, 32, 112, 112])\n",
      "after inv_residual0\t: torch.Size([1, 16, 112, 112])\n",
      "after inv_residual1 #0\t: torch.Size([1, 24, 56, 56])\n",
      "after inv_residual1 #1\t: torch.Size([1, 24, 56, 56])\n",
      "after inv_residual2 #0\t: torch.Size([1, 32, 28, 28])\n",
      "after inv_residual2 #1\t: torch.Size([1, 32, 28, 28])\n",
      "after inv_residual2 #2\t: torch.Size([1, 32, 28, 28])\n",
      "after inv_residual3 #0\t: torch.Size([1, 64, 14, 14])\n",
      "after inv_residual3 #1\t: torch.Size([1, 64, 14, 14])\n",
      "after inv_residual3 #2\t: torch.Size([1, 64, 14, 14])\n",
      "after inv_residual3 #3\t: torch.Size([1, 64, 14, 14])\n",
      "after inv_residual4 #0\t: torch.Size([1, 96, 14, 14])\n",
      "after inv_residual4 #1\t: torch.Size([1, 96, 14, 14])\n",
      "after inv_residual4 #2\t: torch.Size([1, 96, 14, 14])\n",
      "after inv_residual5 #0\t: torch.Size([1, 160, 7, 7])\n",
      "after inv_residual5 #1\t: torch.Size([1, 160, 7, 7])\n",
      "after inv_residual5 #2\t: torch.Size([1, 160, 7, 7])\n",
      "after inv_residual6\t: torch.Size([1, 320, 7, 7])\n",
      "after last_conv\t\t: torch.Size([1, 1280, 7, 7])\n",
      "after avgpool\t\t: torch.Size([1, 1280, 1, 1])\n",
      "after flatten\t\t: torch.Size([1, 1280])\n",
      "after dropout\t\t: torch.Size([1, 1280])\n",
      "after fc\t\t: torch.Size([1, 1000])\n"
     ]
    }
   ],
   "source": [
    "# Codeblock 11\n",
    "mobilenetv2 = MobileNetV2()\n",
    "x = torch.randn(BATCH_SIZE, IN_CHANNELS, IMAGE_SIZE, IMAGE_SIZE)\n",
    "\n",
    "out = mobilenetv2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c78a720",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "MobileNetV2                              [1, 1000]                 --\n",
       "├─Conv: 1-1                              [1, 32, 112, 112]         --\n",
       "│    └─Conv2d: 2-1                       [1, 32, 112, 112]         864\n",
       "│    └─BatchNorm2d: 2-2                  [1, 32, 112, 112]         64\n",
       "│    └─ReLU6: 2-3                        [1, 32, 112, 112]         --\n",
       "├─InvResidualS1: 1-2                     [1, 16, 112, 112]         --\n",
       "│    └─Conv2d: 2-4                       [1, 32, 112, 112]         1,024\n",
       "│    └─BatchNorm2d: 2-5                  [1, 32, 112, 112]         64\n",
       "│    └─ReLU6: 2-6                        [1, 32, 112, 112]         --\n",
       "│    └─Conv2d: 2-7                       [1, 32, 112, 112]         288\n",
       "│    └─BatchNorm2d: 2-8                  [1, 32, 112, 112]         64\n",
       "│    └─ReLU6: 2-9                        [1, 32, 112, 112]         --\n",
       "│    └─Conv2d: 2-10                      [1, 16, 112, 112]         512\n",
       "│    └─BatchNorm2d: 2-11                 [1, 16, 112, 112]         32\n",
       "├─ModuleList: 1-3                        --                        --\n",
       "│    └─InvResidualS2: 2-12               [1, 24, 56, 56]           --\n",
       "│    │    └─Conv2d: 3-1                  [1, 96, 112, 112]         1,536\n",
       "│    │    └─BatchNorm2d: 3-2             [1, 96, 112, 112]         192\n",
       "│    │    └─ReLU6: 3-3                   [1, 96, 112, 112]         --\n",
       "│    │    └─Conv2d: 3-4                  [1, 96, 56, 56]           864\n",
       "│    │    └─BatchNorm2d: 3-5             [1, 96, 56, 56]           192\n",
       "│    │    └─ReLU6: 3-6                   [1, 96, 56, 56]           --\n",
       "│    │    └─Conv2d: 3-7                  [1, 24, 56, 56]           2,304\n",
       "│    │    └─BatchNorm2d: 3-8             [1, 24, 56, 56]           48\n",
       "│    └─InvResidualS1: 2-13               [1, 24, 56, 56]           --\n",
       "│    │    └─Conv2d: 3-9                  [1, 144, 56, 56]          3,456\n",
       "│    │    └─BatchNorm2d: 3-10            [1, 144, 56, 56]          288\n",
       "│    │    └─ReLU6: 3-11                  [1, 144, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-12                 [1, 144, 56, 56]          1,296\n",
       "│    │    └─BatchNorm2d: 3-13            [1, 144, 56, 56]          288\n",
       "│    │    └─ReLU6: 3-14                  [1, 144, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-15                 [1, 24, 56, 56]           3,456\n",
       "│    │    └─BatchNorm2d: 3-16            [1, 24, 56, 56]           48\n",
       "├─ModuleList: 1-4                        --                        --\n",
       "│    └─InvResidualS2: 2-14               [1, 32, 28, 28]           --\n",
       "│    │    └─Conv2d: 3-17                 [1, 144, 56, 56]          3,456\n",
       "│    │    └─BatchNorm2d: 3-18            [1, 144, 56, 56]          288\n",
       "│    │    └─ReLU6: 3-19                  [1, 144, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-20                 [1, 144, 28, 28]          1,296\n",
       "│    │    └─BatchNorm2d: 3-21            [1, 144, 28, 28]          288\n",
       "│    │    └─ReLU6: 3-22                  [1, 144, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-23                 [1, 32, 28, 28]           4,608\n",
       "│    │    └─BatchNorm2d: 3-24            [1, 32, 28, 28]           64\n",
       "│    └─InvResidualS1: 2-15               [1, 32, 28, 28]           --\n",
       "│    │    └─Conv2d: 3-25                 [1, 192, 28, 28]          6,144\n",
       "│    │    └─BatchNorm2d: 3-26            [1, 192, 28, 28]          384\n",
       "│    │    └─ReLU6: 3-27                  [1, 192, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-28                 [1, 192, 28, 28]          1,728\n",
       "│    │    └─BatchNorm2d: 3-29            [1, 192, 28, 28]          384\n",
       "│    │    └─ReLU6: 3-30                  [1, 192, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-31                 [1, 32, 28, 28]           6,144\n",
       "│    │    └─BatchNorm2d: 3-32            [1, 32, 28, 28]           64\n",
       "│    └─InvResidualS1: 2-16               [1, 32, 28, 28]           --\n",
       "│    │    └─Conv2d: 3-33                 [1, 192, 28, 28]          6,144\n",
       "│    │    └─BatchNorm2d: 3-34            [1, 192, 28, 28]          384\n",
       "│    │    └─ReLU6: 3-35                  [1, 192, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-36                 [1, 192, 28, 28]          1,728\n",
       "│    │    └─BatchNorm2d: 3-37            [1, 192, 28, 28]          384\n",
       "│    │    └─ReLU6: 3-38                  [1, 192, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-39                 [1, 32, 28, 28]           6,144\n",
       "│    │    └─BatchNorm2d: 3-40            [1, 32, 28, 28]           64\n",
       "├─ModuleList: 1-5                        --                        --\n",
       "│    └─InvResidualS2: 2-17               [1, 64, 14, 14]           --\n",
       "│    │    └─Conv2d: 3-41                 [1, 192, 28, 28]          6,144\n",
       "│    │    └─BatchNorm2d: 3-42            [1, 192, 28, 28]          384\n",
       "│    │    └─ReLU6: 3-43                  [1, 192, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-44                 [1, 192, 14, 14]          1,728\n",
       "│    │    └─BatchNorm2d: 3-45            [1, 192, 14, 14]          384\n",
       "│    │    └─ReLU6: 3-46                  [1, 192, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-47                 [1, 64, 14, 14]           12,288\n",
       "│    │    └─BatchNorm2d: 3-48            [1, 64, 14, 14]           128\n",
       "│    └─InvResidualS1: 2-18               [1, 64, 14, 14]           --\n",
       "│    │    └─Conv2d: 3-49                 [1, 384, 14, 14]          24,576\n",
       "│    │    └─BatchNorm2d: 3-50            [1, 384, 14, 14]          768\n",
       "│    │    └─ReLU6: 3-51                  [1, 384, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-52                 [1, 384, 14, 14]          3,456\n",
       "│    │    └─BatchNorm2d: 3-53            [1, 384, 14, 14]          768\n",
       "│    │    └─ReLU6: 3-54                  [1, 384, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-55                 [1, 64, 14, 14]           24,576\n",
       "│    │    └─BatchNorm2d: 3-56            [1, 64, 14, 14]           128\n",
       "│    └─InvResidualS1: 2-19               [1, 64, 14, 14]           --\n",
       "│    │    └─Conv2d: 3-57                 [1, 384, 14, 14]          24,576\n",
       "│    │    └─BatchNorm2d: 3-58            [1, 384, 14, 14]          768\n",
       "│    │    └─ReLU6: 3-59                  [1, 384, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-60                 [1, 384, 14, 14]          3,456\n",
       "│    │    └─BatchNorm2d: 3-61            [1, 384, 14, 14]          768\n",
       "│    │    └─ReLU6: 3-62                  [1, 384, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-63                 [1, 64, 14, 14]           24,576\n",
       "│    │    └─BatchNorm2d: 3-64            [1, 64, 14, 14]           128\n",
       "│    └─InvResidualS1: 2-20               [1, 64, 14, 14]           --\n",
       "│    │    └─Conv2d: 3-65                 [1, 384, 14, 14]          24,576\n",
       "│    │    └─BatchNorm2d: 3-66            [1, 384, 14, 14]          768\n",
       "│    │    └─ReLU6: 3-67                  [1, 384, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-68                 [1, 384, 14, 14]          3,456\n",
       "│    │    └─BatchNorm2d: 3-69            [1, 384, 14, 14]          768\n",
       "│    │    └─ReLU6: 3-70                  [1, 384, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-71                 [1, 64, 14, 14]           24,576\n",
       "│    │    └─BatchNorm2d: 3-72            [1, 64, 14, 14]           128\n",
       "├─ModuleList: 1-6                        --                        --\n",
       "│    └─InvResidualS1: 2-21               [1, 96, 14, 14]           --\n",
       "│    │    └─Conv2d: 3-73                 [1, 384, 14, 14]          24,576\n",
       "│    │    └─BatchNorm2d: 3-74            [1, 384, 14, 14]          768\n",
       "│    │    └─ReLU6: 3-75                  [1, 384, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-76                 [1, 384, 14, 14]          3,456\n",
       "│    │    └─BatchNorm2d: 3-77            [1, 384, 14, 14]          768\n",
       "│    │    └─ReLU6: 3-78                  [1, 384, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-79                 [1, 96, 14, 14]           36,864\n",
       "│    │    └─BatchNorm2d: 3-80            [1, 96, 14, 14]           192\n",
       "│    └─InvResidualS1: 2-22               [1, 96, 14, 14]           --\n",
       "│    │    └─Conv2d: 3-81                 [1, 576, 14, 14]          55,296\n",
       "│    │    └─BatchNorm2d: 3-82            [1, 576, 14, 14]          1,152\n",
       "│    │    └─ReLU6: 3-83                  [1, 576, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-84                 [1, 576, 14, 14]          5,184\n",
       "│    │    └─BatchNorm2d: 3-85            [1, 576, 14, 14]          1,152\n",
       "│    │    └─ReLU6: 3-86                  [1, 576, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-87                 [1, 96, 14, 14]           55,296\n",
       "│    │    └─BatchNorm2d: 3-88            [1, 96, 14, 14]           192\n",
       "│    └─InvResidualS1: 2-23               [1, 96, 14, 14]           --\n",
       "│    │    └─Conv2d: 3-89                 [1, 576, 14, 14]          55,296\n",
       "│    │    └─BatchNorm2d: 3-90            [1, 576, 14, 14]          1,152\n",
       "│    │    └─ReLU6: 3-91                  [1, 576, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-92                 [1, 576, 14, 14]          5,184\n",
       "│    │    └─BatchNorm2d: 3-93            [1, 576, 14, 14]          1,152\n",
       "│    │    └─ReLU6: 3-94                  [1, 576, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-95                 [1, 96, 14, 14]           55,296\n",
       "│    │    └─BatchNorm2d: 3-96            [1, 96, 14, 14]           192\n",
       "├─ModuleList: 1-7                        --                        --\n",
       "│    └─InvResidualS2: 2-24               [1, 160, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-97                 [1, 576, 14, 14]          55,296\n",
       "│    │    └─BatchNorm2d: 3-98            [1, 576, 14, 14]          1,152\n",
       "│    │    └─ReLU6: 3-99                  [1, 576, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-100                [1, 576, 7, 7]            5,184\n",
       "│    │    └─BatchNorm2d: 3-101           [1, 576, 7, 7]            1,152\n",
       "│    │    └─ReLU6: 3-102                 [1, 576, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-103                [1, 160, 7, 7]            92,160\n",
       "│    │    └─BatchNorm2d: 3-104           [1, 160, 7, 7]            320\n",
       "│    └─InvResidualS1: 2-25               [1, 160, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-105                [1, 960, 7, 7]            153,600\n",
       "│    │    └─BatchNorm2d: 3-106           [1, 960, 7, 7]            1,920\n",
       "│    │    └─ReLU6: 3-107                 [1, 960, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-108                [1, 960, 7, 7]            8,640\n",
       "│    │    └─BatchNorm2d: 3-109           [1, 960, 7, 7]            1,920\n",
       "│    │    └─ReLU6: 3-110                 [1, 960, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-111                [1, 160, 7, 7]            153,600\n",
       "│    │    └─BatchNorm2d: 3-112           [1, 160, 7, 7]            320\n",
       "│    └─InvResidualS1: 2-26               [1, 160, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-113                [1, 960, 7, 7]            153,600\n",
       "│    │    └─BatchNorm2d: 3-114           [1, 960, 7, 7]            1,920\n",
       "│    │    └─ReLU6: 3-115                 [1, 960, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-116                [1, 960, 7, 7]            8,640\n",
       "│    │    └─BatchNorm2d: 3-117           [1, 960, 7, 7]            1,920\n",
       "│    │    └─ReLU6: 3-118                 [1, 960, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-119                [1, 160, 7, 7]            153,600\n",
       "│    │    └─BatchNorm2d: 3-120           [1, 160, 7, 7]            320\n",
       "├─InvResidualS1: 1-8                     [1, 320, 7, 7]            --\n",
       "│    └─Conv2d: 2-27                      [1, 960, 7, 7]            153,600\n",
       "│    └─BatchNorm2d: 2-28                 [1, 960, 7, 7]            1,920\n",
       "│    └─ReLU6: 2-29                       [1, 960, 7, 7]            --\n",
       "│    └─Conv2d: 2-30                      [1, 960, 7, 7]            8,640\n",
       "│    └─BatchNorm2d: 2-31                 [1, 960, 7, 7]            1,920\n",
       "│    └─ReLU6: 2-32                       [1, 960, 7, 7]            --\n",
       "│    └─Conv2d: 2-33                      [1, 320, 7, 7]            307,200\n",
       "│    └─BatchNorm2d: 2-34                 [1, 320, 7, 7]            640\n",
       "├─Conv: 1-9                              [1, 1280, 7, 7]           --\n",
       "│    └─Conv2d: 2-35                      [1, 1280, 7, 7]           409,600\n",
       "│    └─BatchNorm2d: 2-36                 [1, 1280, 7, 7]           2,560\n",
       "│    └─ReLU6: 2-37                       [1, 1280, 7, 7]           --\n",
       "├─AdaptiveAvgPool2d: 1-10                [1, 1280, 1, 1]           --\n",
       "├─Dropout: 1-11                          [1, 1280]                 --\n",
       "├─Linear: 1-12                           [1, 1000]                 1,281,000\n",
       "==========================================================================================\n",
       "Total params: 3,505,960\n",
       "Trainable params: 3,505,960\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 313.65\n",
       "==========================================================================================\n",
       "Input size (MB): 0.60\n",
       "Forward/backward pass size (MB): 113.28\n",
       "Params size (MB): 14.02\n",
       "Estimated Total Size (MB): 127.91\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Codeblock 12\n",
    "mobilenetv2 = MobileNetV2()\n",
    "summary(mobilenetv2, input_size=(BATCH_SIZE, IN_CHANNELS, IMAGE_SIZE, IMAGE_SIZE))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
